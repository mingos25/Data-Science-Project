{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHeF/brfj9MfjjDyngCwhm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Progetto Finale Data Science - Travel"
      ],
      "metadata": {
        "id": "EqNI8jaiNQR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Il tuo compito sarà seguire ogni punto e commentarlo, mostrandomi di aver capito cosa tu stia facendo. Se alcuni punti si rivelano impossibili spiegami la motivazione. Troverai probabilmente alcuni modelli o tecniche che non hai propriamente studiato. Non preoccuparti, la sperimentazione, la scoperta e il continuo aggiornamento fanno parte del gioco. CANCELLA QUESTO MESSAGGIO PRIMA DI CARICARE IL PROGETTO**"
      ],
      "metadata": {
        "id": "3ZWZwKuGNMNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questo progetto si analizzerà un dataset sulla soddisfazione dei clienti di una compagnia aerea.\n",
        "\n",
        "l'obiettivo è **poter prevedere la soddisfazione degli utenti in base a dei parametri sulla soddisfazione dei servizi della compagnia aerea**"
      ],
      "metadata": {
        "id": "Mc5xdSsnNKVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA (Exploratory data analysis)"
      ],
      "metadata": {
        "id": "iAnq7DLBStSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA SELECTION"
      ],
      "metadata": {
        "id": "wYIgedftS2Qz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in questo progetto verrano caricati due dataset, uno per il training ed uno per il test, fornito dalla traccia su start2impact:"
      ],
      "metadata": {
        "id": "DQ7iNGemS95B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "saranno caricati tutte le librerie python che verranno utilizzate in questo progetto:"
      ],
      "metadata": {
        "id": "MG8pSuaFW60o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n"
      ],
      "metadata": {
        "id": "FkOjSH7ZOSum"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "S'importa i due csv forniti dalla traccia su start2impact. E' stato utilizzato il codice sotto perchè per la creazione del progetto è stato utilizzato con la piattaforma cloud di google Colab:"
      ],
      "metadata": {
        "id": "A7YwzHlPPEa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-PF07FLYcogX",
        "outputId": "3b30386b-d61b-4b5a-c6d9-dc764ef4a48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dafc1387-7848-49ff-962e-691cabf19214\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dafc1387-7848-49ff-962e-691cabf19214\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('test.csv')\n",
        "df_train = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "10wfrPJ9dFFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "id": "4tAeXZNlcPhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "si puoi analizzare che sommando la grandezza dei 2 dataset, il training set rappresenta il 75% dei dati mentre il training set rappresenta il 25% dei dati."
      ],
      "metadata": {
        "id": "GK654-y1nwtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viene dato un primo sguardo ai dati del dataset di training"
      ],
      "metadata": {
        "id": "s_U3jaMlQyOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_train.head(), df_test.head())"
      ],
      "metadata": {
        "id": "CNROoaytT9Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_train.info(), df_test.info())"
      ],
      "metadata": {
        "id": "qnprbIBv1StS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "viene dato uno sguardo alle colonne presenti:"
      ],
      "metadata": {
        "id": "1T9KG_ntouuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_train.columns, df_test.columns)"
      ],
      "metadata": {
        "id": "UdQO2vXiV4Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "viene dato uno sguardo ai valori unici presenti in ogni colonna:"
      ],
      "metadata": {
        "id": "uRDCBlgvoyNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_train.nunique())\n",
        "display(\"valori unici nel test set: \")\n",
        "display(df_test.nunique())\n",
        "\n"
      ],
      "metadata": {
        "id": "zIP8DRj91Ajy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for colonna in df_train.columns:\n",
        "    valori_unici = df_train[colonna].unique()\n",
        "    print(f\"Valori presenti nella variabile '{colonna}' unici: {valori_unici}\")"
      ],
      "metadata": {
        "id": "1OWEYPBpkyfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA CLEANING"
      ],
      "metadata": {
        "id": "GyDNT995fZMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dopo aver dato un primo sguardo al dataset, si può proseguire con il data cleaning:\n",
        "\n",
        "In questa fase verranno applicate modifiche sia al training che al test set, quindi su tutto il dataset, per vari motivi:\n",
        "1.  **Errate interpretazioni delle relazioni tra variabili**: La presenza di dati sporchi o mancanti nel training set può portare a distorcere le relazioni tra le variabili.\n",
        "\n",
        "2.   **Visualizzazioni fuorvianti**: Dati non puliti possono generare grafici che non riflettono accuratamente le distribuzioni e le tendenze reali dei dati, portando a interpretazioni errate.\n",
        "\n",
        "3.   **Destabilizzazione dei modelli**: Dati sporchi possono compromettere la stabilità dei modelli di apprendimento. Questo può portare a overfitting (modello troppo complesso che si adatta ai rumori del training set) o underfitting (modello troppo semplice che non cattura i pattern dei dati), riducendo la robustezza e la capacità di generalizzazione dei modelli\n",
        "\n",
        "# PER IL MOMENTO NON CANCELLARE QUESTO TESTO PIU' IL TESTO INERENTE AL TEST SET, QUANDO UTILIZZERAI IL TEST SET PER FARE LA PREDIZIONE CAPISCI SE FUNZIONA\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vSD_FQ0BX1pm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DATA REDUCTION"
      ],
      "metadata": {
        "id": "13081YKxwGzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si procede a eliminare le variabili non indispensabili o ridondanti in tutto il dataset come:\n",
        "\n",
        "1. **Unnamed: 0**: Questa variabile assegna un ID a ogni riga. Tuttavia, utilizzando pandas, viene automaticamente creato un indice per ogni riga, rendendo questa variabile ridondante.\n",
        "2. **id**: Questa variabile non è indispensabile per il progetto, in quanto non contribuisce all'analisi o alla costruzione del modello\n",
        "\n"
      ],
      "metadata": {
        "id": "IcwOsznvO6Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_feat_clean= df_train.drop(columns=[\"Unnamed: 0\", \"id\"], axis=1)\n",
        "df_test_feat_clean= df_test.drop(columns=[\"Unnamed: 0\", \"id\"], axis=1)\n",
        "\n",
        "df_train_feat_clean"
      ],
      "metadata": {
        "id": "eJBxAPJcPIPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_feat_clean"
      ],
      "metadata": {
        "id": "WAfJbxTzfRhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA CLEANING (DEVI CANCELLARE IL TITOLO DI SOPRA)"
      ],
      "metadata": {
        "id": "H2zL8YuhweLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si procede ad analizzare se sono presenti dei valori nulli (isnull()) o NaN (isna()), verrà effettuato un calcolo in percentuale per fare più chiarezza sui dati mancanti:"
      ],
      "metadata": {
        "id": "xLGqtqxpsNFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "s'inizia con il test set :"
      ],
      "metadata": {
        "id": "NLf7ICjrQVLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_null_percentage(df):\n",
        "  nan_df = (df.isna().sum() / len(df) ) * 100\n",
        "  null_df = (df.isnull().sum() / len(df) ) * 100\n",
        "  return nan_df, null_df"
      ],
      "metadata": {
        "id": "glQv2Zr-lNeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_df_test, null_df_test =  calculate_null_percentage(df_test_feat_clean)\n",
        "\n",
        "nan_df_test, null_df_test\n"
      ],
      "metadata": {
        "id": "oP0BWOnaD85t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "È emerso che valori nulli o NaN sono presenti solo nella variabile *Arrival Delay in Minutes* e rappresentano quasi lo **0.32%** dei valori NaN e nulli, percentuali veramente basse"
      ],
      "metadata": {
        "id": "suwP1P4_uBAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "si analizza il training set:"
      ],
      "metadata": {
        "id": "JFCWI4y7W2qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_df_train, null_df_train =  calculate_null_percentage(df_train_feat_clean)\n",
        "\n",
        "nan_df_train, null_df_train"
      ],
      "metadata": {
        "id": "oolCYHQFnGXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anche nel training set, la variabile *Arrival Delay in Minutes* è l'unica variabile che ha valori nulli o NaN, i quali rappresentano quasi lo **0.30%** dei valori, una percentuale alquanto bassa. Si analizzano righe con valori nulli:"
      ],
      "metadata": {
        "id": "QFf_bIEQP1Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "null_value = df_test_feat_clean.isna()\n",
        "df_test_missing_val = df_test_feat_clean[null_value.any(axis=1)]\n",
        "\n",
        "null_value = df_train_feat_clean.isna()\n",
        "df_train_missing_val = df_train_feat_clean[null_value.any(axis=1)]\n",
        "\n",
        "display(df_test_missing_val, df_train_missing_val)\n"
      ],
      "metadata": {
        "id": "_mQ2q_sbOzT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "È emerso che i valori nulli sono pochi rispetto al numero totale di valori nella variabile, sia nel training set che nel test set. Pertanto, si potrebbe considerare l'eliminazione delle righe contenenti valori nulli in entrambi i dataset, poiché la perdita di dati non influenzerebbe in modo significativo l'integrità dei dataset. Si utilizzerà il metodo *dropna()* su entrambi i dataset:"
      ],
      "metadata": {
        "id": "0w44I4mEhnqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_clean = df_train_feat_clean.dropna()\n",
        "df_test_clean = df_test_feat_clean.dropna()\n"
      ],
      "metadata": {
        "id": "YsZgXBnHfboN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si effettua una controprova per stabilire che tutti i valori nulli sono stati eliminati:"
      ],
      "metadata": {
        "id": "lLlbD2g_qzC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_df_test, null_df_test =  calculate_null_percentage(df_test_clean)\n",
        "nan_df_test, null_df_test"
      ],
      "metadata": {
        "id": "jDCgz4YQqGYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_df_train, null_df_train =  calculate_null_percentage(df_test_clean)\n",
        "\n",
        "nan_df_train, null_df_train"
      ],
      "metadata": {
        "id": "MmvbXzujqOOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I due dataset sono completamente puliti dai valori nulli"
      ],
      "metadata": {
        "id": "bRAX2OkqqXdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA EXPLORATION\n"
      ],
      "metadata": {
        "id": "XQZcKj9Twelq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questa fase verranno rintracciati gli **outliers**. Gli outliers sono dei dati diversi dagli altri che si discostano da una distribuzione generale di una variabile o di un insieme di variabili. Essi possono distorcere le stime dei parametri del modello di apprendimento e possono influenzare le statistiche descrittive (come la media e la deviazione standard) portando a interpretazioni errate dei dati.\n",
        "\n",
        "\n",
        "Prima di iniziare ad analizzare il dataset, è necessario decidere quale dataset utilizzare o se utilizzare entrambi. In questa fase è stato deciso di utilizzare solo il training set perchè se si togliessero gli outliers anche nel test set, si creerebbe un accuretezza falsata perchè si creerebbe un test set ottimale e pulito e l'obiettivo è lasciare i dati di test che assomigliano quanto possibile a quelli che si riceverebbero in un ambiente di produzione.\n",
        "\n",
        "Gli outliers possono essere rintracciati sia da un punto di vista grafico o calcolarlo con i quartili recuperati dal metodo *describe()*. Verranno analizzati da un punto di vista grafico."
      ],
      "metadata": {
        "id": "kQaqK255oHYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.melt(df_train_clean, value_vars=['Gender', 'Customer Type', 'Age', 'Type of Travel',\n",
        "       'Class', 'Flight Distance', 'Inflight wifi service',\n",
        "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
        "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
        "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
        "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
        "       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes'], var_name='Variabile', value_name='Valore')\n",
        "\n",
        "fig, axs = plt.subplots(nrows=11, ncols=2, figsize=(12, 30))\n",
        "axs = axs.flatten()\n",
        "for i, ax in enumerate(axs):\n",
        "    if i < len(df_train_clean.columns):\n",
        "        sns.boxplot(data=df[df['Variabile'] == df_train_clean.columns[i]], ax=ax)\n",
        "        ax.set_title(df_train_clean.columns[i])\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z7RQ-2wOGqjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Osservando i boxplot molte variabili non presentano dei outliers"
      ],
      "metadata": {
        "id": "lY6r7XFin7kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_clean.describe()"
      ],
      "metadata": {
        "id": "a4mlilatwY71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_clean.hist(figsize=(10, 8))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oL-BAghjz9DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_feat_clean_subset = df_train_feat_clean.loc[: , \"Inflight wifi service\":\"Cleanliness\"]\n",
        "sns.boxplot(data=df_train_feat_clean_subset)\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CeB-FDKX2TMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_feat_clean_subset = df_train_feat_clean.loc[: , [\"Departure Delay in Minutes\", \"Arrival Delay in Minutes\"]]\n",
        "sns.boxplot(data=df_train_feat_clean_subset)\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eZlZZvSO2vs7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}